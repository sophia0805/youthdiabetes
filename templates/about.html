<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>About — YouthDiabetes.AI</title>
  <link rel="stylesheet" href="static/style.css">
</head>
<body>
  <div class="container">
    <header class="header">
      <div class="brand">
        <div class="logo"><a href="/"><img src="static/image/logo.png" alt="logo" style="width:28px;height:28px"></a></div>
        <div class="site-title">YouthDiabetes.AI</div>
      </div>
      <nav class="nav">
        <a href="/">Home</a>
        <a href="/risk">Risk</a>
        <a href="/resources">Resources</a>
        <a href="/about" class="active">About</a>
      </nav>
      <button id="hamburger" class="hamburger" aria-label="Open menu">☰</button>
    </header>

    <section class="hero">
      <h1>Youth Diabetes Crisis</h1>
      <p class="muted">Story</p>
    </section>

    <section class="hero">
      <h1>How AI Can Help</h1>
      <p class="muted">Generative AI is reshaping how people live, work, and stay healthy, 
        with notable effects on physical and mental well-being. In healthcare, it can help doctors 
        make better diagnoses, tailor treatments to individual patients, and accelerate drug discovery, potentially improving outcomes and lowering costs for patients and systems alike. Generative AI can also reduce administrative burdens on clinicians, giving them more time for direct care, and enhance access to health information for patients. ([Government Accountability Office][1])
At the same time, these technologies pose health risks if used improperly. AI can give inaccurate or misleading medical or mental health advice, which may delay necessary professional care and harm outcomes, and suffers from “hallucinations” and bias that affect vulnerable populations. ([Government Accountability Office][1]) Chatbots used for mental health support might increase access but also raise concerns about empathy, crisis response, and overreliance without clinician oversight. ([PubMed][2])
Overall, generative AI can support healthier lives when integrated responsibly with strong governance, ethical standards, and collaboration with healthcare professionals, ensuring benefits without compromising safety. ([nationalacademies.org][3])

[1]: https://www.gao.gov/products/gao-24-107634?utm_source=chatgpt.com "Science & Tech Spotlight: Generative AI in Health Care | U.S. GAO"
[2]: https://pubmed.ncbi.nlm.nih.gov/40510413/?utm_source=chatgpt.com "Balancing risks and benefits: clinicians' perspectives on the use of generative AI chatbots in mental healthcare - PubMed"
[3]: https://www.nationalacademies.org/news/2025/04/capturing-the-potential-of-generative-ais-use-in-health-and-medicine-requires-collaboration-and-oversight-consideration-of-risks-says-nam-special-publication?utm_source=chatgpt.com "Capturing the Potential of Generative AI’s Use in Health and Medicine Requires Collaboration and Oversight, Consideration of Risks, Says NAM Special Publication"
</p>
    </section>

    <p class="footer">© 2026 youthdiabetes.ai — style-only demo</p>
  </div>
  <div id="drawer" class="drawer"><div class="panel">
    <a href="/">Home</a>
    <a href="/risk">Risk</a>
    <a href="/resources">Resources</a>
    <a href="/about">About</a>
  </div></div>
  <script src="../js/main.js"></script>
</body>
</html>